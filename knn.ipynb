{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions with k-nearest neighbors on the Iris Flowers Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library for the project\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and load the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "source": [
    "I split in 2 part the dataset (randomly), the first part is the training data and the second part will be use for the validation model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in 2 the dataset \n",
    "def splitcsv(dataset):\n",
    "    validation_data = []\n",
    "    trainning_data = []\n",
    "    for i in range(0,len(dataset)):\n",
    "        rd = random.choice([True, False])\n",
    "        if rd:\n",
    "            trainning_data.append(dataset[i]) \n",
    "        else:\n",
    "            validation_data.append(dataset[i])\n",
    "    return trainning_data, validation_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function from scratch :\n",
    "\n",
    "-Convert string column to float\n",
    "\n",
    "-Convert string column to integer\n",
    "\n",
    "-Find the min and max values for each column\n",
    "\n",
    "-Rescale dataset columns to the range 0-1 (normalization)\n",
    "\n",
    "-Calculate the Euclidean distance between two vectors\n",
    "\n",
    "-Locate the most similar neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        print('[%s] => %d' % (value, i))\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "def distance_euclid(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "def find_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = distance_euclid(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction\n",
    "Make a prediction with neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(train, test_row, num_neighbors):\n",
    "    neighbors = find_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with KNN on Iris Dataset prediction --> row = 5.7,2.9,4.2,1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Iris-virginica] => 0\n[Iris-setosa] => 1\n[Iris-versicolor] => 2\n[Iris-virginica] => 0\n[Iris-setosa] => 1\n[Iris-versicolor] => 2\nData=[5.1, 3.5, 1.4, 0.2, 1], Predicted: 1\nData=[4.9, 3.0, 1.4, 0.2, 1], Predicted: 1\nData=[4.7, 3.2, 1.3, 0.2, 1], Predicted: 1\nData=[4.6, 3.1, 1.5, 0.2, 1], Predicted: 1\nData=[5.4, 3.9, 1.7, 0.4, 1], Predicted: 1\nData=[4.6, 3.4, 1.4, 0.3, 1], Predicted: 1\nData=[4.4, 2.9, 1.4, 0.2, 1], Predicted: 1\nData=[4.9, 3.1, 1.5, 0.1, 1], Predicted: 1\nData=[5.1, 3.5, 1.4, 0.3, 1], Predicted: 1\nData=[5.1, 3.8, 1.5, 0.3, 1], Predicted: 1\nData=[4.6, 3.6, 1.0, 0.2, 1], Predicted: 1\nData=[5.0, 3.0, 1.6, 0.2, 1], Predicted: 1\nData=[5.2, 3.5, 1.5, 0.2, 1], Predicted: 1\nData=[4.7, 3.2, 1.6, 0.2, 1], Predicted: 1\nData=[4.8, 3.1, 1.6, 0.2, 1], Predicted: 1\nData=[5.2, 4.1, 1.5, 0.1, 1], Predicted: 1\nData=[5.5, 4.2, 1.4, 0.2, 1], Predicted: 1\nData=[4.9, 3.1, 1.5, 0.1, 1], Predicted: 1\nData=[5.5, 3.5, 1.3, 0.2, 1], Predicted: 1\nData=[5.0, 3.5, 1.3, 0.3, 1], Predicted: 1\nData=[4.5, 2.3, 1.3, 0.3, 1], Predicted: 2\nData=[4.4, 3.2, 1.3, 0.2, 1], Predicted: 1\nData=[5.0, 3.5, 1.6, 0.6, 1], Predicted: 1\nData=[4.8, 3.0, 1.4, 0.3, 1], Predicted: 1\nData=[5.3, 3.7, 1.5, 0.2, 1], Predicted: 1\nData=[7.0, 3.2, 4.7, 1.4, 2], Predicted: 0\nData=[6.4, 3.2, 4.5, 1.5, 2], Predicted: 0\nData=[6.3, 3.3, 4.7, 1.6, 2], Predicted: 0\nData=[4.9, 2.4, 3.3, 1.0, 2], Predicted: 2\nData=[5.2, 2.7, 3.9, 1.4, 2], Predicted: 2\nData=[6.1, 2.9, 4.7, 1.4, 2], Predicted: 2\nData=[5.6, 2.9, 3.6, 1.3, 2], Predicted: 2\nData=[5.6, 3.0, 4.5, 1.5, 2], Predicted: 2\nData=[6.2, 2.2, 4.5, 1.5, 2], Predicted: 0\nData=[5.6, 2.5, 3.9, 1.1, 2], Predicted: 2\nData=[6.1, 2.8, 4.0, 1.3, 2], Predicted: 2\nData=[6.3, 2.5, 4.9, 1.5, 2], Predicted: 0\nData=[6.4, 2.9, 4.3, 1.3, 2], Predicted: 0\nData=[6.6, 3.0, 4.4, 1.4, 2], Predicted: 0\nData=[5.5, 2.4, 3.8, 1.1, 2], Predicted: 2\nData=[5.5, 2.4, 3.7, 1.0, 2], Predicted: 2\nData=[6.0, 3.4, 4.5, 1.6, 2], Predicted: 0\nData=[5.6, 3.0, 4.1, 1.3, 2], Predicted: 2\nData=[6.1, 3.0, 4.6, 1.4, 2], Predicted: 2\nData=[5.8, 2.6, 4.0, 1.2, 2], Predicted: 2\nData=[5.6, 2.7, 4.2, 1.3, 2], Predicted: 2\nData=[5.7, 2.9, 4.2, 1.3, 2], Predicted: 2\nData=[6.2, 2.9, 4.3, 1.3, 2], Predicted: 0\nData=[5.7, 2.8, 4.1, 1.3, 2], Predicted: 2\nData=[6.3, 3.3, 6.0, 2.5, 0], Predicted: 0\nData=[5.8, 2.7, 5.1, 1.9, 0], Predicted: 2\nData=[7.1, 3.0, 5.9, 2.1, 0], Predicted: 0\nData=[6.3, 2.9, 5.6, 1.8, 0], Predicted: 0\nData=[7.6, 3.0, 6.6, 2.1, 0], Predicted: 0\nData=[4.9, 2.5, 4.5, 1.7, 0], Predicted: 2\nData=[6.7, 2.5, 5.8, 1.8, 0], Predicted: 2\nData=[7.2, 3.6, 6.1, 2.5, 0], Predicted: 0\nData=[6.5, 3.2, 5.1, 2.0, 0], Predicted: 0\nData=[6.8, 3.0, 5.5, 2.1, 0], Predicted: 2\nData=[5.8, 2.8, 5.1, 2.4, 0], Predicted: 2\nData=[7.7, 3.8, 6.7, 2.2, 0], Predicted: 0\nData=[5.6, 2.8, 4.9, 2.0, 0], Predicted: 2\nData=[7.7, 2.8, 6.7, 2.0, 0], Predicted: 0\nData=[6.1, 3.0, 4.9, 1.8, 0], Predicted: 2\nData=[6.4, 2.8, 5.6, 2.1, 0], Predicted: 0\nData=[6.1, 2.6, 5.6, 1.4, 0], Predicted: 0\nData=[6.3, 3.4, 5.6, 2.4, 0], Predicted: 0\nData=[6.4, 3.1, 5.5, 1.8, 0], Predicted: 0\nData=[6.9, 3.1, 5.4, 2.1, 0], Predicted: 0\nData=[5.8, 2.7, 5.1, 1.9, 0], Predicted: 2\nData=[6.2, 3.4, 5.4, 2.3, 0], Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "dataset_train, dataset_validation = splitcsv(dataset)\n",
    "for i in range(len(dataset_train[0])-1):\n",
    "\tconvert_str_column_to_float(dataset_train, i)\n",
    "for i in range(len(dataset_validation[0])-1):\n",
    "\tconvert_str_column_to_float(dataset_validation, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset_train, len(dataset_train[0])-1)\n",
    "str_column_to_int(dataset_validation, len(dataset_validation[0])-1)\n",
    "# define model parameter\n",
    "num_neighbors = 5\n",
    "\n",
    "# predict the label\n",
    "for j in range(0,len(dataset_validation)):\n",
    "\tlabel = 0\n",
    "\tlabel = prediction(dataset_train, dataset_validation[j][0:3], num_neighbors)\n",
    "\tprint('Data=%s, Predicted: %s' % (dataset_validation[j], label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d65f8af9b1347936d5c0a715a1a101b7602968bee42a1bc2161adfc924f1cbb0"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}